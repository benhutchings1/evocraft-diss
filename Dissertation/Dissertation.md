---
title: Generation of diverse Minecraft structures with evolutionary algorithms
author: Ben Hutchings
date: May 2023
geometry: a4paper
geometry: margin=1in
---
# Abstract
\newpage
#  Introduction
Procedural content generation (PCG) is a technique used in video game design and other creative fields, such as art and music. The technique allows creators to generate a near infinite amount of content based on a few rules, constraints, and parameters. This allows games to be highly replayable, feeling more unique and unpredictable. An example of effective PCG is in No Man’s Sky [@no_man_sky_2016], a universe exploration game, which can generate $2^{64}$ ($~18*10^{18}$) worlds, each ~203 km$^2$ [@newhouse_2016]. Compared to one the biggest non-generated games, ARMA 3 [@arma_3_2012], which has a map size of 270 km$^2$ [@carlson_2013], shows how much more content can be generated by PCG.

PCG does come with some downsides, mainly sacrificing quality control. A traditional game would have game designers’ hand-designing all aspects of the game, meaning the output is predetermined and easily controllable. Since PCG is designed to be unending, it is impossible to brute force quality check. Unlike other types of PCG, like art and music, the design of content in games is first and foremost based around playability, with artistic qualities being a secondary objective. Many existing machine learning PCG techniques allow for small variations in the content generated, which in a medium like music makes no difference to the overall quality, but small variations in game design can lead to the game being unplayable. But playability is not a binary scale, as [@koster_2013] explains, there exists a "golden section" of game design which is the perfect balance novelty and familiarity, which is pleasing for our brains and therefore better to play.

Another drawback to PCG is processing costs and generation speed. According to the steam hardware survey [@steam_2023], which is the most comprehensive hardware census and continuously updated, there is still a massive range in hardware capabilities being used, with strongest graphics card being ~2400% stronger than the weakest [@userbenchmark]. The higher the hardware requirements for a game, the larger the proportion of users unable to run the game, alienating a portion of the customer base.

An approach to PCG is using machine learning. Outside of games, machine learning based PCG has made massive leaps forward. Models such as DALL-E 2 [@ramesh2022hierarchical] can generate completely unique photo-realistic images from a text description, and ChatGPT [@chatgpt_2022] can generate text answers to almost any question. These models have been so successful due in large part to the enormous amount of data they have been trained on and the huge complexity of the models, which presents problems for PCG in games. For DALL-E/ChatGPT to generate whatever is requested, they needed to have seen something similar to base their response off of. This is problematic for game world generation, as there exists no dataset big or diverse enough to adequately train these models [@summerville2018procedural]. Large-scale deep learning models are also extremely computationally expensive, heavily affecting the hardware requirements.

Another issue is the idea of creativity. Models such as DALL-E and ChatGPT do produce unique outputs, but the output is based on many existing sources. For these models this is not a big problem because of the huge variety of training data which allows the models to draw on many sources to generate new content [@ibmai_2015]. Games on the other hand generally have the same recognizable styles and artifacts throughout the world. A model splicing these together could lead to a disjointed world and recognizable from other games, leading to lower immersion. 

The fundamental problem with PCG is the the *state-explosion* problem, where as the size of the generated content increases, the search space increases exponentially and brute force solutions become intractable [@Godefroid_2002]. Since it is impossible to verify if a solution is the best solution, an approximate solution is required. One approach to this is through the use of genetic algorithms (GA). GA’s take inspiration from the biological process of natural selection and use it to evolve a solution to a problem, using heuristics to guide a population towards a solution. Evolving a solution instead of training from past solutions comes with certain advantages. By having an algorithm which is controlled by the rules of a system rather than being trained on existing examples allows the model to come up with new unique solutions, rather than rehashing existing solutions.

This paper will be experimenting with NEAT [@6790655], which is a type of genetic algorithm, and how the performance is affected by different levels of novelty. I will be investigating this within the context of the EvoCraft [@grbic2020evocraft] challenge, a PCG challenge for MineCraft [@persson_2023]. Theses concepts will be explained in more detail.

## Aims and Objectives
Aim: Investigate how varying levels of novelty affects the diversity of procedurally generated structures in Minecraft
Objectives:</br>
    1. Investigate other competition entries for the EvoCraft challenge</br>
    2. Research procedural content and novelty search techniques</br>
    3. Implement fitness functions to evaluate single structures</br>
    4. Experiment with varying levels of novelty</br>
    5. Evaluate multi-structure cities to see effects of novelty</br>

# Background
## Minecraft
Minecraft is a 3D, open-world, sandbox, voxel-based video game. Each voxel, called a block, can be broken and replaced to build structures, allowing players to apply their creativity. Minecraft uses PCG and world seeds to create a unique world which is 3.6 billion blocks$^2$ [@whitworth_2021], allowing players virtually infinite space to explore and build. Because of the open-ended nature of the game and the simplicity of interactions with the world, Minecraft has become a platform for many AI challenges, including mineRL. This competition focused on an agent within Minecraft which has to complete a variety of tasks in an unknown environment. Because there is no one defined task, the algorithm has to be able to complete many smaller problems, with the eventual goal of improving research into general intelligence. 

For interactions between Python and Minecraft world I will be using a Minecraft server with a Bukkit [@bukkit_2010] plugin called RaspberryJuice installed and the McPi Python library to communicate with it. Bukkit is a server modification tool with an API which allows developers to easily create server plugins. The RaspberryJuice plugin converts Python commands into Java commands which can be processed by the Minecraft server. The McPi library simply sends Python commands to the RaspberryJuice plugin, which then places them in the Minecraft environment.

### The EvoCraft Challenge
To investigate genetic algorithms for PCG, I am using on the EvoCraft Challenge as a framework to base the project on. The EvoCraft challenge brief is to create an open-ended algorithm which is capable of creating novel and increasingly complex structures in MineCraft. These algorithms have to be unending and should aim to diverge over time rather than slow down and become repetitive. One of the drawbacks of PGC was the lack of quality control, and the problem with infinitely generating content becoming repetitive over time. This challenge aims to use evolving algorithms to keep generating content which keeps diverging and becoming more interesting. 

## Other EvoCraft Entries 
### Evocraft PCGNN
[@beukman2023hierarchically] were came runners up in the EvoCraft competition with their endless city generator. Their approach broke a city down into the component 'levels', starting from the lowest level, the house and garden. To generate a house and garden they broke this down into 4 components: the house structure, roof, decorations, and garden. They then used a PCGNN (Procedural Content Generation using Neat and Novelty search) approach to generate each of these components. The house, roof, and decorations are all generated as 3d tilemaps to be placed in-world. The house consists of walls, empty space, and entrance, the roof consists of a design covering the area beneath it, and the decorations consists of decoration blocks filling floor space inside the house. The garden works slightly differently as it is a 2d tilemap covering an area with flowers, grass, and trees. They then used these component houses and gardens to create a town. A town is its own generated 2D tilemap of houses, gardens and roads @@image in appendix@@, where are road connects all the houses in the town. They then placed many towns together to create a city, which could grow endlessly. 
@@pic in appendix@@  

### simple_minecraft_evolver 
[@real-itu_2021]</br>
The simple Minecraft evolver is basic NEAT implementation which aims to build a tower towards a gold block in the air. Early generations start by building towers in random directions, but as they evolve they move more towards the gold block. 


## Neural Networks
A neural network is a type of machine learning technique which is inspired by the human brain. A neural network consists of collections of neurons, organized in layers, which are connected to each other. An example is shown in @fig:desc, where each neuron is depicted as a node on the graph and the connections between neurons as vertices. In a traditional neural network, each neuron (apart from the input neurons) has a weighted connection to some nodes from the previous layer ($n_{prev}$). The equation for the value of a neuron is shown in @@figure, where $W_i$ is the weight to a node, $X_i$ is the value of the node, and $b$ is a bias.  
![Figure @@: An example neural network\label{label}](Images/Neural_network_explain.png){#fig:desc}
$$y=f(\sum_{i=0}^{n_{prev}} w_{i}x_{i}+b)$$

To make a prediction, some input values are set to the input nodes values, which are used to calculate the value of the next layer's neurons. This repeats until the output layer is reached. The values from the output layer is the prediction. A traditional neural network can learn by adjusting the weights and bias in the neurons. 

## NEAT + Novely Search
NeuroEvolution of Augmenting Topologies (NEAT) is type of genetic algorithm (GA) which heavily mimics biological evolution to increase the complexity of neural networks. Unlike traditional neural networks, where the structure of the network is fixed, NEAT works by increasing the complexity of the network over time. NEAT uses a direct encoding method where all nodes, weights, and biases from each individual are all encoded into a "genome", which can be used to recreate the neural network (the phenotype). To begin many individuals created, called a population. These initial individuals have no hidden nodes and are just weighted connections between the input and output nodes. Each individual is evaluated using a fitness function and given a fitness score. The top individuals with the highest fitness score are taken and used to create a new population. 
To create a new population the individuals undergo "crossover". This is where two genomes are combined to create an "offspring" by randomly combining their genomes together. This process is not done blindly though, as this is much more likely to create a non-functioning neural network rather than improving the performance. To crossover two genomes they first have to share a similar enough genome to allow them to crossover. This is done by recording each network's evolution history and if the genomes share a similar enough history then they can crossover. Once offspring have been created through crossover, they undergo mutation. Mutation is the process of making random changes to an individual's genome, which can show as new nodes or changes to weights in the phenotype. The aim of NEAT is, through random mutation and crossover, to evolve (make random changes) a solution to a problem [@heidenreich_2019].         

There is however a problem with this evolution process, a population's fitness score can easily become stuck in a local maxima. This comes from a deeper ideological difference between biological evolution and genetic algorithms. The purpose of an GA is to reach a global maximum fitness, whereas biological evolution aims to both evolve fit individuals which will survive, but will also spread out and diverse over generations. If a species does not diversify then it is more vulnerable to diseases and sudden changes to the environment [@Greenwald_2009]. For an GA to get out of a local maxima it must first drop in fitness score before finding another genome structure which would allow it to reach the global maxima. Traditional GA algorithms don't allows for this as any drop in fitness score would kill the individual and stop it from evolving further. Here we take a note from biological evolution and promote diversity, called novelty search. Novelty search gives a higher fitness to individuals which have significantly changed from the population. This lets individuals change and explore the search space without being killed, leading to a higher probability of success. [@6790655]

## Reinforcement Learning PCG
Reinforcement learning (RL) is a type of machine learning composed of three key elements: an agent, the environment, a reward. RL uses a trial-and-error method with an agent interacting with an environment. An agent makes an action within and environment and will either be rewarded, if the the action was a positive action, and punished, if the action was negative. The eventual goal for a RL agent is to learn a policy, which is a mapping from input states to output actions. The agent starts with random actions and getting experience, in the form of state-action-reward, which is used to update the policy of the agent. Eventually the agent aims to maximize the cumulative reward signal by maintaining a balance between exploring, to learn new experiences, and exploitation, leveraging existing techniques.

RL gains many of the same benefits as genetic algorithms. Just like GA's, RL's require no large dataset and therefore don't have any of the intrinsic biases and creativity issues which come with it. There are some subtle differences between the two algorithms. RL can sometimes suffer trying to reach a global maxima in reward/fitness. Because RL is one agent learning over many iterations, if the agent chooses a strategy which works well, but only reaches a local maxima, it would have to unlearn that entire strategy and come up with a new one for it to reach a global maxima. A GA on the other hand has many individuals in a population, each which can explore their own routes (promoted through novelty search). Each route that ends in a local maxima will be killed in favour of a route which produces a global maxima, therefore having a higher likelihood of reaching the global maxima [@joy_2019]. While the RL model approach has the potential to be effective in this project, the properties of NEAT make it more desirable. 

## General Adveserial Networks 
A General Adversarial Network (GAN) is type of deep learning network, composed of two neural networks: A generator and discriminator. The role of a generator is, once trained on training data, to generate more examples which resemble the training data. The role of the discriminator is to tell the difference between examples from the training data and the examples generated by the generator [@Park_2022]. 

GAN's have some advantages which make them very powerful in certain situations. Since the training data is only used for examples, there is no need to label the data. Once a GAN is fully trained, both parts of the network can be used. A well trained generator can generate data very similar to the training data. DALLE-2, a realistic image generator, uses a GAN-like network structure to create unique photo-realistic images. The discriminator can also be used to detecting discrepancies in data, for example medical imaging, quality control, and fraud detection. There are some issues with GAN's. They require vast amounts of training data and the wider the range of outputs being generated, the higher the size of the training data required. They are also a black box and very hard to reason why it came up with what it did, making it very hard to fix problems like diversity of output and garbled data. GAN's naturally lose detail from the input to the output, which makes the generated content lose some finer details [@hui_2018]. This is not a problem for creative works as some minor variation has no affect on the quality of the output, but does have an effect on PCG for games. Some minor changes to game generation can leave it unplayable and useless. The combination of not being able to generate at a very fine level, being a black box, and requiring huge amounts of training data, it can be very hard to reliable produce quality content for games. Because of these disadvantages a GAN approach is unsuitable for this project.

# Implementation
I have chosen to do this project in Python. While the competitors (Java, C++, R...) are much faster than the core Python modules, there are libraries, such as NumPy, which are written in C and are extremely quick. This means it can perform well on large datasets, making it a favorite for data scientists. Because it is a popular data science language, there is also a large collection of machine learning libraries supported to help development.

The aim of the project is to procedurally create diverse Minecraft structures. Taking a note from [@beukman2023hierarchically], the structure generation is broken down into 2 parts, generating the base of the house and generating the roof, an example of this is in @@figure. For each of these parts, a different model is used. The development of these models is broken down into three main objectives: model design, the fitness functions, and novelty experimentation.
@@Maybe an image describing this?

## House Model
The aim of the house model is to generate a 3D block for the roof to sit on. In the first design iteration, the house model simply predicted a full 3D block. The issue with this was the model had to be taught to leave a gap in the centre and 1 block for the outside wall. Just learning this took the model a long time and it was not guaranteed, which severely impacted the design of the house. Another issue was the generation speed. Producing a full 3D block was very computationally intense, especially for larger structures. Another approach took advantage of the wall being 1 block thick and empty inside. This allows for the wall of the 3D block to be mapped to a 2D tilemap. Now the model can predict the 2D tilemap and always keeps the correct house structure while being much more computationally efficient.
![Figure @@: 3D house tilemap is mapped to a 2D wall tilemap](Images/block.png)

## Roof Model
The roof model, similar to the house model, initially predicted a 3D roof but had the same issues as the house model. The other approach to this is very similar to the house model. Since the roof should be one block thick and cover the area underneath, it can be shown as a 2D tilemap describing the height of each block in the roof. An example of a heightmap is shown in @@figure.    
![Figure @@: 2D heightmap mapped to a 3D construction](Images/roof.png)

## Model hyperparameters
Hyperparameters are the parameters which control the learning process for each population, such as mutation rate and population size. One of these parameters is the input/output sizes of the model, which must be a fixed value for all individuals in a population at all times. In the first design iteration, the model predicted each block in the structure in one go. This meant the output size of the model each block used in the structure, and because the output size is fixed, the size of the structure was fixed. This massively reduced the diversity of the structures and was visually boring. 

The next design iteration took a different approach. Instead of predicting all the blocks in one go, the model predicted one block at a time, denoted ŷ. This removes the limitation on the structure size, since the model can be run an unlimited number of times. This does increase the overhead as making a prediction from the model is an intense process, but it is worth it to improve the quality of the structures. Since both the house and roof model produce 2D tilemaps, they work in similar ways. An 2D tilemap is first randomized and padded by 1. To predict the first ŷ, the model is given the blocks surrounding it (denoted $x_{surr}$), shown in @@figure. The output size of the model (ŷ), is each block which is possible to place. Minecraft contains 133 blocks which are suitable for the structures, and therefore is the outputs size. 
![Figure @@: Description of model inputs](Images/model_input.png)

Since the models can produce structures of arbitrary size, the models need to know what size structure is being created to control the patterns, therefore the height, length and width of the structure is passed into the model as well. Also since the model has no memory, it is also given the xy coordinates of ŷ for more information about what is being generated. The house model has another input. Since the model is predicting the blocks to place, there needs to be some control over this, otherwise the model will only ever predict one block. Therefore the house model is also given 3 seed blocks which it should use to build the structure.

## Fitness Functions
A fitness function is used to evaluate the quality of a candidate solution, to help it reach a desired solution. According to [@mallawaarachchi_2017] a fitness function should be:</br>
- Clearly defined: it should be easy to understand and provide meaningful insight into the performance.</br>
- Intuitive: Better solutions should get a better score and visa-versa </br>
- Efficiently implemented: NEAT requires many generations to evolve a good solution, so the fitness function should not be a bottleneck</br>
- Sensitive: Should be able to distinguish between slightly better and slightly worse solutions to allow a gradual movement towards a better solution</br>
For each model the fitness is calculated by combining the novelty score and structure score (explained in more detail below). The ratio of these combinations decides the level of novelty in the population.

### Structure Scoring
#### House Model 
To start calculating a house score, the components of the desired structure have to be broken down. When deciding fitness functions it is important to limit the scope of what can be expected, there is always more detail that can be added to the scoring. The purpose of the scoring is to highlight the important parts of a structure and guide the genome towards the desired output, but leaving enough flexibility to allow for creativity. A balance between control and creativity. Each of the component scoring functions generate a value between $0<x<1$ and the average is used to calculate the overall structure score.
The fitness functions I decided on were:
1. A bounding wall </br>
An important part of a house is a complete wall with no air-gaps. While the wall cannot be structurally wrong, the model can still place airgaps which must be minimized. The score is calculated by taking the percentage of blocks that aren't air.</br>

2. A door</br>
There should be a door on ground level to enter the structure. This is the only score which is either 0 (no usable door) or 1 (usable door).</br>

3. Seed blocks</br>
The 3 seed blocks inputs are to control the types of blocks which are generated by the structure. This scores models higher which prioritises using blocks from the three seed blocks given. For each seed block which is in the top 5 blocks used, 1/3 is added to the score. </br>

4. Symmetry</br>
In almost everything considered beautiful, there is some element of symmetry. It has been well documented that humans find symmetry much more attractive and soothing to look at [@Huang_2018]. Instead of limiting my model and forcing symmetry in one axis, I am checking both x & y axes and choosing the one which has the highest symmetry. The symmetry is calculated by comparing the percentage of equal blocks on both sides of the axis, giving a value between 0 and 1. </br>

5. Block Variance</br>
Block variance promotes a higher variance of blocks, by scoring a structure higher if more unique blocks are used, the equation for which is below. The model gets a higher score the more blocks it uses, up to 3 blocks. Above 3 blocks the score caps at 3/4, chosen because it is better than 2 blocks (2/3) but not better than 3 blocks. This was done to prevent the the models using too many blocks and making a cluttered design, but not too few blocks..
```
int x: size(unique)
if (x <= 3){ 
    score=x/3
}else {
    score = 3/4
}
```
The final house structure score is calculated as the average of: bounding wall, door, symmetry, block variance scores.

#### Roof Model
Since this is a simple structure with a lower search space, it is very easy for the fitness functions to be too controlling. For example, if the scores maximize for sloped roofs, then only sloped roofs will be generated, therefore it was very important to have gentle control.
The structure scores:</br>
1. Compliance</br>
This ensures the heightmap generated fits within the limits I have set. For example, if the maximum height set is 5 blocks and the heightmap contains a height greater than 5, then the solution doesn't pass the compliance check. This fitness is either a 0 (failed the check) or 1 (passed the check). </br>

2. Symmetry</br>
Just like the house model, I am maximizing for symmetry in the xy axes.</br>

3. Visual Complexity</br>
This is the fitness for quality checking and making the solution more interesting. To make the solutions more interesting I am maximizing for complexity in the surface. This is achieved by rewarding changes in height over flatness. This is accomplished by counting the ratio of changes in height of 1 vs no changes in height. I am purposely not counting changes in height of more than 1, as that will leave gaps and ruin the look of the roof. An example of low complexity vs high complexity is shown in @@figure. I chose this solution over rewarding specific types of structure, like flat or triangle-sloped roofs, to allow for more flexibility. </br>
![Figure @@: High complexity vs low complexity heightmaps](Images/heightmap_complexity.png)

### Novelty Scoring
As previously mentioned, the novelty score is necessary to allow a population to escape any local maxima and reach a higher fitness. When finding the novelty of a genome, it needs to be compared to its closest relations. If a genomes if very different to its closest relatives, then it will have a high novelty score. An individual cannot be compared to the whole population, it has to be compared to its closest relatives. If an individual is only compared to distant relatives, which are completely different, it will always have a high novelty score. This means the novelty score will stop reflecting how the individual has changed, therefore an individual can only be compared to its closest relatives. To make this comparison, the novelty score of an individual is he average genetic distance between the *k*-nearest-neighbors (KNN), equation shown in @@figure. After some testing, I found $k = \frac{2}{3} * size(population)$ gave the best comparison. 
$$NoveltyScore(x)=\frac{1}{k}\sum_{i=0}^{k}dist(x, \mu_{i})$$

Another potential issue with novelty scoring is backtracking or cycling. This can occur when a population repeatedly cycles between the same behavior space, which can repeatedly give a high novelty score, and therefore high population fitness. To a population this is an easy solution for reaching a high fitness, but does mean the population will not continue to explore the problem search space, therefore not improving. A solution to this is archiving highly novel members of the previous generation, then comparing to them when calculating novelty scores. If a population cycles, the population novelty score will be reduced and individuals who escape the cycle can improve [@salehi2022geodesics]. To choose which individuals are added to the archive, a threshold is created ($\alpha$), and any individuals over that threshold are kept. From some simple testing, $\alpha=0.85$ archived individuals at the correct rate.

## City construction
Part of the aim of the project was to use procedural content generation to generate multi-structure content, e.g. a city. To generate a city using a trained house and roof populations, individuals are randomly selected to place a house and roof. By using all individuals from the population, the novelty of a population can come across in the constructions. The generated houses start off at the same sizes, but every time a building is placed there is a 5% chance for the sizes to be adjusted. This gives a gradually chances the dimensions of the houses, instead of having randomly sized buildings next to each other, mimicking real city.

A core part of the project is maximizing diversity while maintaining the structural form, therefore this needs to be measured across the city.
1. Structure Score distribution
The structure score is my measurement for the structural form of a building. If all the generated structures in a city have a low structure score then the constructions will be poorly made and will look worse.

2. Block Distribution
The visual quality of the structures are broken down into two metrics, colors and patterns. The color distribution is easier to measure because each block has roughly a different color. Therefore if the structure has a high distribution in blocks used, the color distribution will be higher and therefore will be more diverse. 

3. Pattern Measurement
Pattern measurement is how often a structure design is repeated .This is harder to measure because the buildings aren't all the same dimensions and are each made of different blocks. Since patterns can feasibly only be compared with structures of the same size, they are grouped by the dimensions and a pairwise comparison is made within the groups. Next each structure is passed through the skimage labelling function@@cite. This function labels connectivity between the elements of an array. An element is connected to another element if it is a neighbor and they have the same value. An example of connectivity is shown in @@figure. By labelling the connected regions in the image it is much easier to identify patterns between structure, regardless if different blocks are used. The labelled structures are then directly compared and the percentage similarity is used as the pattern similarity value.      
![Figure @@: Randomised pattern and labelled random pattern](Images/pattern_labelling.png)

4. Generation Time
One of the drawbacks of PCG, identified in the introduction, was the generation speeds. The immersion of a game can be broken if the user has to wait too long for the world to be generated, therefore the generation speed needs to be minimized.

# Evaluation
## Experimentation
The aim of the experimentation is to understand the effects of different levels of novelty in populations for building structures. When an individual's fitness is calculated, their structure and novelty scores are calculated and the ratio of these are used for the fitness. The ratio of structure:novelty determines the level of novelty in the population. To experiment with the novelty, different populations will be trained, each with a different level of novelty. The structure scores throughout training will be collected and compared to show the effects of novelty throughout the training process. For each level of novelty a house and roof model will be trained twice. Since the models are inherently random, running the generations multiple times was necessary to show a population wasn't an anomaly. The levels of novelty that will be compared are: no novelty (control), low novelty (1:4 novelty:structure), high novelty (4:1 novelty:structure), and full novelty (1:0 novelty:structure). 
Each house model trained had a population of 20 and each roof model trained had a population of 100. Having a larger population increases the chances of a positive mutation, but also increases the hardware requirements. The neat-python library does not have GPU support and can struggle at larger populations, so was limited to those population sizes. Each model was trained for 2000 generations and was then trained for longer if the population was still showing improvement. The training was then stopped when the models have not improved in the last 50 generations, because there should be some improvement in that time. Unless the models reaches the the highest possible score (1.0), they can always train for longer because there is a chance they might improve more, but there has to be a cut off. 

## Training Comparisons
@@fig shows an overview of the training results. The graph shows the maximum population average over a 20 generation window. This means every generation, the previous 20 generations are taken, and the average is taken over that window, equation shown in @@figure. As shown later, this is necessary because the graphs are quite noisy. If just only max value was taken, without the window, all the averages are very similar and don't reflect the state of the population. The graph shows that there is quite a difference between runs, but overall the results line up with what was expected, with the high novelty model regularly having the highest performance and the full novelty model having the lowest performance. @@maybe more?

![Figure @@: Graph comparing max average structure score between runs](Images/final_graphs/avg_results.png)

### Control Model
![Figure @@: No novelty (control) training - house model](Images/final_graphs/house/control_house.png)
![Figure @@: No novelty (control) training - roof model](Images/final_graphs/roof/control_roof.png)

The control model shows a very typical learning process without novelty, where there is a region of rapid improvement at the start as the model can easily make improvement, but then reaches a local maxima, where the average score stays. Without the novelty mechanic, the model is stuck there and cannot improve. Since this has happened over all 4 graphs, we can be confident this would happen a majority of the time. As shown in @@figure, the success of the control model does vary and can sometimes surpass models with novelty, but it is very dependant on when it reaches the first local maxima, and would not improve with more generations, whereas a model with novelty might. 

### Low Novelty Model
![Figure @@: Low novelty training - house model](Images/final_graphs/house/low_nov_house.png)
![Figure @@: Low novelty training - roof model](Images/final_graphs/roof/low_nov_roof.png)

The low novelty models show lots of similarities with the control models, which is to be expected. There is more variation where the model has tried to escape a local maxima, especially evident in the run 2 of the house model around generation 250 - 750, where there is a significant dip with a large amount of variation. This period also has a large max-min gap (shown in grey). The large gap between the lines is evidence of novelty in the population, where the best and worse models have diverged. We should expect this max-min gap to appear more in the roof model as the population 5x larger and can spread out much easier. 

### High novelty Model
![Figure @@: High novelty training - house model](Images/final_graphs/house/high_nov_house.png)
![Figure @@: High novelty training - roof model](Images/final_graphs/roof/high_nov_roof.png)

The high novelty house model clearly shows a lots of activity during training, whereas the roof model shows much less. My hypothesis is that since the roof is much simpler and a smaller search space, the model either found a global maxima or a local maxima which it couldn't escape from. What the graph does show is a large max-min gap which is again evident of novelty. On the other hand, the house model clearly shows how novelty has caused many dips in the structure score. Especially evident around generation 400 on run 1, where there is a significant dip, rise in the middle, and dip again. 

### Full Novelty Model
![Figure @@: Full novelty training - house model](Images/final_graphs/house/full_nov_house.png)
![Figure @@: Full novelty training - roof model](Images/final_graphs/roof/full_nov_roof.png)
Because these models had no structure score feedback, only novelty score, there is little progression through the training. These models are randomly hoping to stumble across the correct solution and there are times, like in run 1 of the house model around generation 1750, where the model has found a decent solution. Unfortunately since the model didn't know it had improved, it quickly evolved away from that solution instead of improving on it. Run 2 of the roof model does appear to show the model retaining the score for a significant period. This could be because the model was evolving changes which had no effect on the score and therefore didn't reduce/improve the score.

## Multi-structure Comparisons
To populate the datasets for comparison, 20,000 structures are generated using each novelty type. Since some of the metrics rely on grouping building sizes, it is important there is a large number of structures to get an accurate comparison.
### Structure Score Distribution
![Figure @@: House Structure Score Distribution in generated structures](Images/final_graphs/city/house_scores.png)
![Figure @@: Roof Structure Score Distribution in generated structures](Images/final_graphs/city/roof_scores.png)

### Block Distribution
![Figure @@: Block Distributions in generated structures](Images/final_graphs/city/block_freq.png)

## Pattern Variety
![Figure @@: Pattern variety in generated structures](Images/final_graphs/city/variance_comp.png)

## Generation Time
![Figure @@: Generation time in generated structures](Images/final_graphs/city/times.png)


# Future Work
- Due to hardware requirements and time pressure I could only run the models twice
- work on other structures
# References

\end{document}